{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4e62d1-0bef-4fee-91dd-c0c928a76a83",
   "metadata": {},
   "source": [
    "# üêº 2. With a Little Help from My Pandas API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e83bf9-9bc1-4292-8db1-1147957be5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykx as kx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96474e60-21a2-42f4-9765-9a1eae57c19e",
   "metadata": {},
   "source": [
    "## Traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be67f31d-6eea-4343-9a21-025e9e72cf3e",
   "metadata": {},
   "source": [
    "If we aim to enhance performance, we should let kdb handle the heavy lifting. This involves sticking to the PyKX object and avoiding the use of `pd()`. How dow it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4e15d-c11a-4d96-ad6d-9b3895588baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = kx.q.read.csv(\"data/traffic.csv\", \"IPSJS\", \",\", True)\n",
    "traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5ab8e-fed4-42a4-889c-922e31789fb5",
   "metadata": {},
   "source": [
    "Now, let's identify the errors to initiate the migration of the pandas code into PyKX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60351dca-7af5-4f6f-a79f-772bafbde43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = traffic[traffic['error'] == 'N']\n",
    "traffic = traffic.set_index(['fecha'])\n",
    "traffic_mad = traffic[['carga']].groupby(['fecha']).mean()\n",
    "traffic_mad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a70696-6a6a-4774-8d4d-f1425db4752c",
   "metadata": {},
   "source": [
    "Wait a minute, it works! Fortunately, PyKX has made a significant effort to make this library Python-first. There's a Pandas API that allows us to interact with PyKX tables as if they were Pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00ea1f-5da9-4a69-afe5-2b1a7f954880",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e770290-5636-49bf-982f-90ded3f1ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.read.csv(\"data/weather.csv\", \"DUIFFFFFFFF\", \",\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a089eaf-afdb-42ad-90e5-73eb5ab385d7",
   "metadata": {},
   "source": [
    "Does that mean we can keep the exact same code? Happy days!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd2965-856e-468b-ac00-6ce97164697c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather[weather['precipitacion'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96dfe3-f33b-46cb-8f7e-078f504587e1",
   "metadata": {},
   "source": [
    "Not really! The Pandas API is still evolving, so you might encounter functionality that has not been implemented yet. However, you can always switch back and forth, converting to a Pandas dataframe, applying the expression as is, and then returning to the PyKX object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7dd16-23d5-4f3c-91e9-11d61369d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.pd()\n",
    "weather = weather[weather['precipitacion'].notnull()]\n",
    "weather = kx.toq(weather.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa351628-c3d9-4176-9409-e572d0c1c680",
   "metadata": {},
   "source": [
    "Unfortunately, this incurs a performance penalty. Switching objects between the q and Python spaces is not free. If you prefer to stick with the PyKX object, further training with PyKX is necessary. In this scenario, we could have used the following expression to achieve the same goal:\n",
    "```python\n",
    "weather = weather[getattr(kx.q, 'not')(weather['precipitacion'] == kx.q('0n'))]\n",
    "```\n",
    "This is an exceptionally noisy case due to the peculiarities of `not`, but I thought it would be nice to illustrate it anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80518ad4-a9fc-46ae-a066-f842bad6c61b",
   "metadata": {},
   "source": [
    "The remaining instructions are perfectly fine and do not require further adaptations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94c61a-977e-4a09-92d6-6df421e0a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['fecha'] = weather['fecha'] + weather['hora']\n",
    "weather = weather.set_index(['fecha'])\n",
    "weather_mad = weather[['precipitacion']].groupby(['fecha']).mean()\n",
    "weather_mad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4a30f-c704-4cc2-831f-067348dc4bd9",
   "metadata": {},
   "source": [
    "## All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8445719d-d0aa-41b6-a3f1-0f2ddec165de",
   "metadata": {},
   "source": [
    "What about prefix operations, such as `merge_asof`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a304d3-c3d2-418e-9902-628849064d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "traffic_weather = pd.merge_asof(traffic_mad, weather_mad, on='fecha', direction='backward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd341645-f754-4a48-b7ec-2a4e58ee04e6",
   "metadata": {},
   "source": [
    "Fortunately, PyKX supplies an infix variant to make the adaptation less painful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beda30d-71c6-458d-86c0-23ee22af0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traffic_weather = pd.merge_asof(traffic_mad, weather_mad, on='fecha', direction='backward')\n",
    "traffic_weather = traffic_mad.merge_asof(weather_mad, on='fecha', direction='backward')\n",
    "traffic_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3deb2e-4b43-4fc4-b092-fdb5a9fb2dc5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d5ac7-e1b2-4687-a2c8-e80764ef304d",
   "metadata": {},
   "source": [
    "Now it's time to leverage the rich Python ecosystem. A slight tweak is all it takes to retrieve the dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bd5ac-6d7b-4673-a6c6-6daa0ff0e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_weather = traffic_weather.pd().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87d965-10c0-4dc1-a36d-1b1ff81a9326",
   "metadata": {},
   "source": [
    "... and we are ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7756c09-bcdb-4176-ab7b-7f8b9e3f360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "to_quarter = lambda x: int((x.hour * 60 + x.minute) / 15)\n",
    "traffic_weather['hora'] = traffic_weather['fecha'].dt.time.apply(to_quarter)\n",
    "\n",
    "X = traffic_weather[['hora', 'precipitacion']]\n",
    "y = traffic_weather['carga']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test, predictions, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2)  # Diagonal line for reference\n",
    "plt.xlabel('Actual Traffic Load')\n",
    "plt.ylabel('Predicted Traffic Load')\n",
    "plt.title('Actual vs. Predicted Traffic Load')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f1ed08-0aa5-4b25-bc9a-db7d48dfe874",
   "metadata": {},
   "source": [
    "## What Next?\n",
    "* We can go far with the Pandas API\n",
    "* Understanding the core api and grasping q would become necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6f14c-8815-4ca6-b283-96e11a6a82f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykx",
   "language": "python",
   "name": "pykx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
